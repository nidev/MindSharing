Chain Engine에서 사용하는 감정 어휘 분석을 위한 처리 과정이다.

간략히 전처리(preprocessing) => 태그(tagging) => 결합(jointing) => 어휘 이미지 탐색(looking) => 관계 분석(identifying) => 수치화(quantifying) => 정규화(normalizing) => 학습(feeding back) => 결과 제공(reporting) 단계를 거쳐서 이루어진다.

# 버전 정보

## 2014-Q1
가칭 Chain Engine(체인 엔진) 프로젝트 설계.

이미 제작된 형태소 분석기를 사용하고, 기계적으로 글을 읽고 이해하는 시스템을 구성하기로 함.

장소, 시간, 감탄사 등을 최대한 배제하고 주어와 어떤 대상, 감정표현과의 관계를 위주로 파악하며, 안은 문장 등을 고려해서 주어절을 주어로 인식할 수 있는 능력을 목표로 제작한다.


## 2013-Q4
SylphEngine(실프 엔진) 종료.

Lossy search(뒤의 단어를 삭제하며 체언을 찾는 알고리즘)로 어휘 사전을 단순하게 만들려고 시도했으나, 어휘 간의 관계 파악에는 많은 어려움이 있음.


## 2013-Q3
SlyphEngine(실프 엔진)이라는 이름으로 프로토타입을 만들어냄.

프로토타입은 긍정 어휘 사전과 부정 어휘 사전을 사용해서 검색하는 것을 목표로한다.

# 체인 엔진 알고리즘 개요

문장의 표현은 복잡한 것처럼 보이지만, 실제로 초등학교 1학년 정도의 이해 수준을 생각하면 복잡한 문장에서도 핵심어를 얻어낼 수 있다.

유치원생은 선생님이 말한 문장을 모두 이해하는 것이 아니라, 앞에서의 전제 조건이나 준비 문구를 모두 생략한 채 마지막에 결정적인 핵심 표현만을 잡고 따라한다.

이해를 못하고 따라하는 경우에도, 반복되는 학습을 통해 앞에서 선생님이 말한 말이 어떤 의미인지 이해하게 되고 자연스럽게 문장의 이해 범위가 확장된다.

이때 아이들이 사용할 수 있는 간단한 표현들을 찾아보면,

{{{
	철수는 밥을 먹는다.
	나쁜 사람을 따라가면 안된다.
	착한 아이가 되어야한다.
	나는 철수입니다.
	얘가 나를 때렸다.
	기분이 어떻니? /  좋아요!
	친구가 친구를 때리는 것은 나쁘다.
	꽃이 참 예뻐요.
	너무 맛없어요.
}}}

일반적으로 'Subject는 Adject/Verb하다.', 'Subject는 Adject/Verb되다.' 꼴로 간단히 이루어지는 표현이 많으며, '~~하는 것'과 같은 경우에도 비교적 표현이 간단하다.

따라서 체인 엔진에서는 약 5~6세 정도 어린이가 이해할 수 있는 수준의 문장으로 간단히 줄이고, 어휘 사전을 통해 각 단어의 이미지를 파악한 다음, 제한된 결합 조건을 사용하여 서술어와 서술어간의 관계를 파악할 것이다.

SNS에서 나타나는 단문 텍스트들에 복잡한 문장구조가 나타나지 않고, 문단의 길이가 그리 길지 않은 점을 고려할 때 이 알고리즘은 충분할 것으로 사료되나, 이는 실험을 통해 밝혀내야한다.

형태소 분석기를 사용해 한국어 조사를 사용해 각 명사 어휘, 체언의 품사를 확인하고 조사를 모두 삭제한다음, 어휘 객체에 조사의 의미를 갖고 있는 태그를 달고 있는 객체만을 남긴다.

예를 들어, 위의 예문으로 든 '나쁜 사람을 따라가면 안된다'의 경우는 이 단계에서 다음과 같이 변환된다.

{{{
	[ 나쁘다(형용사) + 사람(객체) ]-<객체> [따라가다]-<행동> [면]-<다음 서술어 확인> [안된다]-<보조 행동어>
}}}

이렇게 변환된 배열을 탐색하면서 인과 관계를 파악하면 다음과 같이 다시 요약이 가능하다.

{{{
	[나쁜 사람] [따라가다] [그 행동은 안된다]
}}}

이 글에서 추출된 감정 형용사는 '나쁘다' 정도이지만, '행동을 금지한다'라는 행동을 함께 감정에 영향을 미치는 요소로 파악할 수 있다면 감정 표현에 용이할 것이다.

다른 예로, '친구가 친구를 때리는 것은 나쁘다.'이라는 표현에 안긴 표현을 봐보자.

{{{
	[친구]-<주어> [친구]-<목적어> [때리다]-<행동> [것은]-<문장 주어 표시> [나쁘다]-<형용사>
}}}

'것' 이라는 표현 때문에 앞의 주어로 시작하여 것까지 부분은 한 덩어리로 뭉쳐진다.

{{{
	[ [친구]-<주어> [친구]-<목적어> [때리다]-<행동> ]-<주어> [나쁘다]-<형용사>
}}}

마치 수학의 (5*2 + 3) + 5 와 같은 연산을 연상시킨다. 기본적으로 여기에서 사용하는 알고리즘은 국어를 수학적 연산을 모방한 언어의 연산으로 처리하는 것에 목표를 하고 있다. 이러한 처리 방법이 과연 트위터 실시간 분석에 필요한 연산 소요 시간을 만들어낼지는 실험을 통해 분석하게 된다.


# 자료 구조
## EmoUnit 가 가지고 있는 속성들
* WordTag : 어휘를 분류하기 위한 태그들이다. 형태소 분석기에서 제공하는 품사 태그를 최대한 단순화하여 처리하기 용이하도록 가공한다.
* EPower : 감정의 세기를 나타내는 Enumurate 값이다.

# 처리 과정
## 전처리(preprocessing)

감정처리를 위해 입력되는 문장은, 사람이 읽고 쓰는 자연어이다. 이 문장 자체는 단순히 바이트의 배열에 그치지 않으므로, 의미 분석을 위해서는 형태소 분석을 해야하고, 그 전에 필요한 작업을 수행해야한다.

엔진에 데이터를 제공하기 전에, 클라이언트가 먼저 해결해주어야할 과제가 있다.

 * 링크 제거: 웹페이지 링크는 분석의 관심사가 아니기 때문에 제거한다.
 * 해시태그 제거: 해시태그는 정보를 분류하기위한 메타 데이터이므로 제거한다.
 * 한국어가 포함되지 않은 문장 제거: 외국어로 이루어진 문장은 처리하지않는다.
 * (트위터) @사용자이름 을 제거: 사용자 간의 대화에 관심이 있는 경우는 아니기 때문에, 제거한다.
 * 지나치게 짧은 글을 제거: 감탄사만 포함하거나, '밥 먹었음'처럼 지나치게 간결한 글은 분석 시간만 소비하므로 제외한다.

 이렇게 걸러낸 SNS 글들을, 클라이언트가 엔진으로 한번에 묶어서 보낸다. 현재는 문단을 자동으로 구별하는 기능이 없다.

 이렇게 수신된 데이터는 엔진에서 따옴표를 해체하는 작업을 통해 알고리즘 적용에 무리가 없도록 수정된다. 전처리 작업이 모두 완료되면, 형태소 분석기를 사용해 형태소로 모두 나눈다.

### 미구현 기능

 문단 자동 구별

 따옴표 해체

## 태그(tagging)

형태소 분석기로 분석된 어휘를, 분석기에서 파악한 품사에 맞춰 Chain Engine에서 사용하는 태그로 변환한다. 단, 이때는, EmoUnit.Wordtag 에 포함된 모든 태그를 사용하는 건 아니다.

엔진에서 사용하는 형태소 분석기는, 기분석된 형태소 데이터를 바탕으로 분석하여 결과를 내주면서, 대부분 문법적인 요소를 그대로 갖고 왔기 때문에 감정 분석에 큰 관계가 없는 데이터가 많다.

따라서 주어진 조건에 따라, 내부의 마커로 변환하여여 '결합' 단계에서 어휘들이 잘 뭉쳐질 수 있도록 하는 편이 처리에 용이하다.

### 태그 변환 목록
괄호 안은 꼬꼬마 형태소 분석기의 태그이다.

편의상 결합 단계에서 사용하는 목적어 어휘(Object)와 주어 어휘(Subject) 태그를 미리 빌려 표현하기로 한다.

(표로 다시 작성할 것)

 * 부사(MAG): EQueryTool.java 에 정의된 함수를 사용해 어떤 마커를 설정할지 결정한다. 다음에 오는 감정 어휘의 값을 반전하는 InvertNextDesc 마커, 강화하는 NextDescEnhancer 마커, 감소하는 NextDescReducer 마커를 결정하며, 그 외의 모든 부사는 Skip 마커로 변한한다.
 * 동사/보조동사(VV/VXV/VX): 동사는 모두 VerbMarker로 태그한다.
 * 형용사/보조형용사(VA/VXA): 형용사는 모두 AdjectMakrer로 태그한다.
 * 의존적 종결어미(ECD): NetxDescDepender 로 태그하고, 관계 분석 단계에서 다시 판단한다.
 * 관형사(MDT/MDN): DeterminerMarker로 태그하고, 결합 단계에서 명사들의 덩어리인 Object 또는 Subject 태그를 가진 객체에 합쳐진다. (미구현)
 * 문장마침(EFN): Skip으로 태그한다. 중요한 정보는 아니다.
 * 주어를 나타내는 조사(JKS/JX): SubjectTrailMarker로 태그하고, 결합 단계에서 이 앞에 나오는 Object나 NounMarker로 태그된 어휘를 주어로 가져간다.
 * 목적어를 나타내는 조사(JKO): ObjectTrailMarker로 태그하고, 앞에 있는 Object나 NounMarker로 태그된 어휘를 주어로 가져간다.
 * 대명사(NP): ReferenceMarker로 태그하고, 관계 분석 단계에서 지칭하는 대상을 파악한다.
 * 인명과 고유명사를 포함한 모든 명사와 체언("NNG", "XR", "XSN", "NNP", "NNB"): NounMarker로 표시한다.

### 미구현 기능

없음

## 결합(jointing)

태그 단계에서 분석한 결과를 바탕으로 어휘와 어휘를 결합하고, 사용되지 않은 어휘를 제거한다.

이 단계에서 동사와 형용사는 서술어로 합쳐지며, 부사는 서술어의 강도에 영향을 미칠 수 있는 경우만 남는다. 그리고 주어를 Subject로 태그한다.

명사와 바로 인접한 명사는 합쳐져서 한 덩어리로 되고 Object로 태그된다. 만약에 Subject 태그가 이 단계에서 남지 않는 경우 휴리스틱을 사용해 가장 앞에 나오는 Object를 주어로 간주한다. 만약 없다면 '나'라는 가상의 주어를 삽입한다.

### 미구현 기능 

없음

## 어휘 이미지 탐색(looking)

이미지 탐색은 사전에 정의된 기본 감정 어휘를 데이터베이스에서 찾아보는 단계이다. 

## 관계 분석(identifying)

## 수치화(quantifying) 

## 정규화(normalizing) 

감정 수치는 로그를 사용해서 정규화한다. 최소값은 0 (10base log, 1), 최대값은 2(10base log, 100)이다. 모든 감정 벡터는 양의 정수이다.
로그를 사용하는 이유는 감정값 상승에 대한 폭이, 선형함수에 비해서 적기 때문이다.

이 단계에서, 정수로 표현된 태그값들을 모두 상용로그로 정규화한다.

전체적으로 감정 벡터를 확인한 후, 네거티브가 강세인지 포지티브가 강세인지 파악한 다음에 강세인 쪽으로 보정을 한다. 보정 작업은 (강세 감정의 로그값 평균)*(0.1)^x 을 더해 전체적으로 조율한다.
이때 x는 문단 전체의 단어 수를 자연로그값을 정수로 내림한 값이다. 따라서 문단이 길어질 수록 보정에 추가된 값은 감소한다. 

이는 문단이 길어질변환 목록로 감정 정보를 거의 기억하지 못한다는 부분에 착안한다. (관련 논문 파악) 사람이 인지 가능한 정보에는 한계가 존재한다.

## 학습(feeding back) 


이 작업에서 피드백된 결과는 다시 데이터베이스의 별도의 테이블로 되돌려보낸다.
매번 학습된 결과는 데이터베이스내에 각 단어별로 각 행을 새롭게 구성하며, 감정값을 가져올 때는 이 값들을 모두 테이블에서 가져와 종합적인 값을 제공한다.
각 값은 시간에 비례하여 감소되는, 역비례 관계를 사용해 변환하여 사용한다.

시간이 흐를 수록 사람의 기억은 사라지며, 감정에 대한 정도도 감소하기 때문이다. 이렇게 하여, 과거에 대한 기억을 조금씩 잊고 새로운 형태를 반영할 수 있는 지능을 갖게 된다.

## 결과 제공(reporting)

ResultProcessor 생성자에 EParagraph 객체를 넘겨주면서 JSON데이터를 생성한다.

종합적인 분석 결과를 제공함과 동시에, 원문과 문장내에서 발견한 감정 표현 들의 raw값을 제공할 수 있도록 완성하였다.
 


